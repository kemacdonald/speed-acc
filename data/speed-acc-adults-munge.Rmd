---
title: "Speed-Acc Adults Data Munging"
author: "Kyle MacDonald & Aviva Blonder"
date: "August 4, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, warning=F, cache=F, message=F, sanitize = T)
```

This script munges eye-tracking data for an experiment comparing speed-accuracy tradeoffs when establishing reference in real-time. We vary the information value and saliency of the center fixation and measure the effects on accuracy and RT.

```{r setup2} 
rm(list = ls())
library(dplyr); library(readr); library(magrittr)
library(ggplot2); library(tidyr); library(knitr)
library(langcog); library(lme4); library(directlabels)
library(lazyeval); source("helper_functions/et_helper.R")
theme_set(theme_bw())
```

Load data and join with trial information (timing, left/right/center images, target info) and with participant info.

```{r load data}
#### read in processed data
d <- read_csv("3_final_merged_data/speed_acc_processed_adult_data.csv")

#### strip .avi and .jpg from stimulus
d$stimulus <- gsub(pattern = ".jpg", "", x = d$stimulus)
d$stimulus <- gsub(pattern = ".avi", "", x = d$stimulus)

### remove validation trial
d %<>% filter(stimulus != "Validation")

#### join trial info
trialinfo_d <- read_csv("../data/trial_info/speed-acc-adult-trial-info.csv")
d %<>% left_join(., trialinfo_d, by = "stimulus")

#### join subject info
subinfo_df <- read_csv("demographics/speed-acc-adult-runsheet.csv")
d %<>% left_join(subinfo_df, by = "subid")
```

### Filter out unusable participants 

```{r filter out participants with bad data}
##calculate percentage of non-looks - that is, looking away from the screen entirely.
##offscreen == TRUE if x is 0 and y is 1050, so higher bad_looks are worse
d_screentime <- transform(d, offscreen = ((x == 0 & y == 1050) | is.na(x) | is.na(y))) %>%
  select(subid, t, offscreen) %>%
  group_by(subid) %>%
  summarise(bad_looks = sum(offscreen, na.rm = TRUE), total_timeslices = n())

d_screentime <- transform(d_screentime, percent_bad_looks = bad_looks/total_timeslices)

##filter out participants more than 3 standard dev away from mean screentime
sd_ss <- sd(d_screentime$percent_bad_looks)
mean_ss <- mean(d_screentime$percent_bad_looks)

d %<>% left_join(., d_screentime, by = "subid")

d$keep <- ifelse(d$percent_bad_looks > (3*sd_ss + mean_ss), 'exclude', 'include')
```

Now we make a table of participant information and trial numbers.

```{r}
d %>% select(subid, source_name, gender, dot, notes) %>% 
  unique() %>% 
  group_by(subid, gender, dot) %>% 
  summarise(n_trials = n()) %>% 
  kable()
```

## Data cleaning/munging

Here we label Areas of Interest to be Left Picture, Right Picture, and the Center Fixation. We also add trial number variable.

### ROIs

Plot the distribution of looking across x-y coordinates. This is a useful check that participants were looking where we thought they should be, and it helps us find the AOIs for data analysis. 

```{r, eval = F}
ggplot(aes(x = x, y = y), data = d) +
  geom_density2d() +
  xlim(0, 1000) +
  ylim(0, 1250)
```

### Add trial numbers

We have 4 blocks of 24 trials, so `r 4 * 24` total trials. To add the trial numbers we first get each unique trial name and the time it started. Then we sort by the time each trial started, and bind the trial numbers. Finally, we join the trial number information with the rest of the eye movement data.

```{r add trial numbers}
n_blocks <- 4
n_trials_in_block <- 24
n_trials_exp <- n_blocks * n_trials_in_block
tr.num <- 1:n_trials_exp

# build a function that takes in a participant's data frame and returns the df with trial numbers added
add.tr.nums.fun <- function (df, n_trials) {
  
  df %<>% select(subid, source_name, t) %>% 
    arrange(t) %>% 
    select(subid, source_name) %>% 
    unique() %>% 
    mutate(tr.num = 1:n_trials)
  
  return(df)
}

# now we apply the add trials function to each subid's data frame using the do() operator 
d %<>% 
  group_by(subid) %>% 
  do(add.tr.nums.fun(., n_trials = n_trials_exp)) %>% 
  left_join(x = d, y = ., by = c("subid", "source_name"))
```

### Flag left/right/center looking based on ROIs

The bounds of the ROIs are generated by visual inspection of the distribution of looks in the task

```{r flag l/r/c looking}
d %<>%
  mutate(gaze_target = ifelse(x >= 0 & x <= 500  & y >= 0 & y <= 600, "left",
                              ifelse(x > 500 & x <= 1000 & y >= 0 & y <= 600, "right",
                                     ifelse(x >= 250 & x <= 750 & y > 700 & y <= 1200, "center",
                                            "away"))))
```

Make a table of proportion looking to each area of interest: Left, Right, Center, and Away

```{r}
d %>% 
  filter(is.na(gaze_target) == F) %>% 
  group_by(gaze_target) %>% 
  summarise(count_looks = n()) %>% 
  mutate(total_looks = sum(count_looks),
         prop_looks = round(count_looks / total_looks, 2)) %>% 
  kable()
```

Hmm, participants are "away" on 11% of the trials. What's going on here? Plot "away" looks, so we can visually inspect.

```{r plot aways}
ggplot(aes(x = x, y = y), data = filter(d, gaze_target == "away")) +
  geom_density2d() +
  xlim(0, 1000) +
  ylim(0, 1250)
```

There's a pretty heavy concentration of looking to the top left of the screen. We think that this is a "catch-all" for any looks the ET could not measure. So we just filter these out for our analyses. 

### Score each trial: RT and Accuracy of first shift

Filter out "away" looks and create some useful variables: condition, target side of the screen, and whether the participant was looking at the target vs. distracter at each time point.

And for our RT analyses, we need to mark the critical onset for each trial. Here we mark three time points of interest. Time relative to the:

1. center fixation appearing on the screen
2. sentence onset
3. target noun onset

```{r}
center.fix.onset <- 1 # experiment was programmed such that center fixation appeared 1 sec after trial onset

d %<>% filter(gaze_target != "away", is.na(gaze_target) == F) %>% 
  mutate(t.stim = ifelse(t.stim == 0, 0, round(t.stim, digits = 3)),
         condition = ifelse(center == "text" & audio == "no-audio", "text-no-audio", center),
         target_side = ifelse(target_image == left_image, "left", "right"),
         target_looking = ifelse(gaze_target == "center", "center",
                                 ifelse(gaze_target == target_side, "target", 
                                        "distracter")),
         t.rel.noun = t.stim - noun_onset_sec_1,
         t.rel.center.fixation = t.stim - center.fix.onset,
         t.rel.sentence = t.stim - sentence_onset_sec)
```

### Flag where participant was looking at each of the critical points in the trial 

In the next set of chunks, we will condense the timecourse information into fewer bits. Specifically, we want to get the information about each participants' first shift on every trial using three different critical onset points. The three onsets of interest are: 

* center fixation (when the center target appeared on the screen)
* sentence onset (when the carrier phrase "Look! Where's the ________" began)
* noun onset (the start of the target noun in the sentence)

```{r flag gaze target at crit onsets for each trial}
# create a temporary copy of the data frame to join at each step
d.orig <- d

# this is how many rows we expect to have after creating the three new response variables
n_row_final <- nrow(d.orig) * 3

# noun onset
d <- d.orig %>% 
  filter(t.rel.noun > 0) %>%
  group_by(tr.num, subid) %>% 
  do(filter(., t.rel.noun == min(t.rel.noun))) %>% 
  mutate(response = target_looking,
         response_onset_type = "noun") %>% 
  select(subid, tr.num, response, response_onset_type) %>% 
  left_join(d.orig, ., by = c("subid", "tr.num"))

# center fixation
d <- d.orig %>% 
  filter(t.rel.center.fixation > 0) %>%
  group_by(tr.num, subid) %>% 
  do(filter(., t.rel.center.fixation == min(t.rel.center.fixation))) %>% 
  mutate(response = target_looking,
         response_onset_type = "center.fixation") %>%
  select(subid, tr.num, response, response_onset_type) %>% 
  left_join(d.orig, ., by = c("subid", "tr.num")) %>% 
  bind_rows(d, .)

# sentence onset
d <- d.orig %>% 
  filter(t.rel.sentence > 0) %>%
  group_by(tr.num, subid) %>% 
  do(filter(., t.rel.sentence == min(t.rel.sentence))) %>% 
  mutate(response = target_looking,
         response_onset_type = "sentence") %>% 
  select(subid, tr.num, response, response_onset_type) %>% 
  left_join(d.orig, ., by = c("subid", "tr.num")) %>% 
  bind_rows(d, .)

# check if we end up with the expected number of rows
nrow(d) == n_row_final
```

Next, we need to compute RT for each trial. Here I've created a somewhat unwieldy score trial function. 

The function takes in a data frame for each trial and computes (1) an RT and (2) whether the shift was correct vs. incorrect. You can tell the function what onset value from which you want to compute RT. The different onset values are:

* noun 
* center_fixation
* sentence

```{r score trial function}
score_trial <- function(trial_df, crit_onset_type = "noun") {
  # filter trial to keep just that onset type
  trial_df %<>% filter(response_onset_type == crit_onset_type)
  
  # build variables to index each trial
  response.type.index <- paste0(crit_onset_type, ".onset") 
  t.filter.type <- paste0("t.rel.", crit_onset_type, " > 0")
  t.select.type <- paste0("t.rel.", crit_onset_type)

  # check if there is a shift in the trial after the critical onset
  # and record where the shift started and ended
  crit.window.responses <- trial_df %>% 
    filter_(t.filter.type) %>% 
    select_("target_looking", t.select.type) %>% 
    group_by(target_looking) %>% 
    summarise_(min_t = interp(~ min(x), x = as.name(t.select.type))) %>% 
    arrange(min_t)
  
  # store info about the shift
  shift.start <- crit.window.responses$target_looking[1]
  shift.info <-paste(crit.window.responses$target_looking[1], crit.window.responses$target_looking[2],
                     sep = "-")
  
  # check if there is only one "response" in the target_looking vector
  # if 1, then there was no shift (i.e., no change from response at crit.onset)
  if (nrow(crit.window.responses) == 1) {
    trial_score <- trial_df %>% 
      mutate(rt = NA, shift_type = "no_shift") %>% 
      select(rt, shift_type) 
  } else {
    # get the earliest time point when target looking switches from the critical onset value 
    trial_score <- trial_df %>% 
      filter_(t.filter.type) %>% 
      filter(target_looking != shift.start) %>% 
      select_(t.select.type, "target_looking") %>% 
      group_by(target_looking) %>% 
      summarise_(rt = interp(~ min(x), x = as.name(t.select.type))) %>% 
      filter(rt == min(rt)) %>% 
      mutate(shift_type = ifelse(shift.info == "center-target", "C_T", 
                                 ifelse(shift.info == "center-distracter", "C_D",
                                        ifelse(shift.info == "target-distracter", "T_D",
                                               ifelse(shift.info== "target-center", "T_C",
                                                      ifelse(shift.info == "distracter-target", "D_T",
                                                             ifelse(shift.info == "distracter-center", "D_C")))))),
             shift_accuracy = ifelse(shift_type == "C_T", "correct", "incorrect")) %>%
      select(rt, shift_type, shift_accuracy) 
  }
  
  # add the rt and score to the trial data frame
  trial_df <- cbind(trial_df, trial_score)
  
  return(trial_df)
}
```

Now we apply the score trial function to each trial for each participant in the tidy data frame using the do() functionality in dplyr. Note that we are using the .$ index to use a variable from the piped data frame as an argument to the score trial function.

```{r}
d %<>% 
  group_by(subid, tr.num, response_onset_type) %>% 
  do(score_trial(., crit_onset_type = .$response_onset_type))
```

Check the distribution of shift types over the different response types

```{r check freq of each shift}
d %>% 
  select(subid, tr.num, response_onset_type, shift_type) %>% 
  unique() %>% 
  group_by(response_onset_type, shift_type) %>% 
  count() %>% 
  kable()
```

Now things look good. We have an RT, a shift type, and a correct/incorrect value for each trial based on three different critical onset points in the trial (i.e., center fixation, sentence, and noun onset)

### Write tidy data to .csv file

Before writing to .csv, we split the data into the timecourse information and first shift information. 

```{r}
# timecourse
d.timecourse <- filter(d, response_onset_type == "noun")

# first shift
d.fs <- d %>% 
  select(subid, tr.num, condition, dot:reason_excluded, response:shift_accuracy) %>% 
  unique()
```


```{r}
write_csv(d.timecourse, path = "3_final_merged_data/speed_acc_adult_timecourse_tidy.csv")
write_csv(d.fs, path = "3_final_merged_data/speed_acc_adult_fstshift_tidy.csv")
```

