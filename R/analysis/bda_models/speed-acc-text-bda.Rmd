---
title: "Speed-acc Text BDA"
output: html_document
---

## Setup

This document contains the codebase for the bayesian data analysis in Experiment 2 ('Speed-acc-text') of the paper, "An information-seeking account of children's eye movements during grounded signed and spoken language comprehension."

```{r set global_options, include=FALSE}
library(here)
source(here::here("R/helper_functions/libraries_and_functions.R"))
source(here::here("R/helper_functions/ewma_helper_funs.R"))

data_path <- "data/3_final_merged_data/first_shifts/"
ewma_path <- "data/3_final_merged_data/ewma_output/"
hddm_path <- "data/3_final_merged_data/hddm_output/"
write_path <- "data/3_final_merged_data/bda_posterior_samples/"

options(mc.cores=parallel::detectCores())
set.seed (3875)
```

## Read data

```{r read data}
d <- read_csv(here::here(data_path, "speed_acc_adult_text_fstshift_tidy.csv"))
d_asl <- read_csv(here::here(data_path, "speed-acc-child-trio-fst-shift.csv"))
```

```{r clean datasets to merge}
d_asl %<>% 
  filter(language_modality == "ASL" & age_code == "adult") %>% 
  mutate(subid = as.character(Sub.Num),
         tr.num = Tr.Num, 
         rt = RT_sec,
         shift_type = trial_type,
         condition = language_modality, 
         hearing_status = hearing_status_participant,
         response_onset_type = "noun") %>% 
  rename(target_image = clean_target_img) %>% 
  select(subid, tr.num, rt, shift_type, hearing_status, condition, response_onset_type, target_image)

d %<>%
  mutate(hearing_status = "hearing") %>% 
  select(subid, tr.num, rt, shift_type, hearing_status, condition, response_onset_type, target_image)
```

Now merge ASL and spoken language data.

```{r merge asl and english data}
d %<>% bind_rows(., d_asl) %>% 
  mutate(shift_accuracy = ifelse(shift_type == "C_T", "correct", "incorrect"),
         correct = as.integer(ifelse(shift_accuracy == "correct", 1, 0)),
         log_rt = log(rt))
```

## Accuracy model

```{r}
m_acc <- d %>% 
  filter(response_onset_type == "noun") %>% 
  stan_glmer(correct ~ condition + (condition | subid) + (target_image | condition), 
  data = .,
  family = binomial(link = "logit"), 
  prior = normal(0, 2),
  prior_intercept = normal(0, 1),
  prior_covariance = decov(regularization = 2), 
  adapt_delta = 0.99,
  chains = 4)

samples_text_acc <- m_acc %>% 
  as.data.frame() %>% as_tibble() %>% 
  dplyr::rename(bullseye = `(Intercept)`,
                face = conditionface,
                text = conditiontext,
                text_no_audio = `conditiontext-no-audio`) %>% 
  select(bullseye:text_no_audio)
```

## RT model

```{r}
m_rt <- d %>% 
  filter(shift_accuracy == "correct", response_onset_type == "noun") %>% 
  stan_glmer(log_rt ~ condition + (condition | subid) + (target_image | condition), 
  family = gaussian(),
  data = .,
  prior = normal(0, 2), 
  prior_intercept = normal(0, 5),
  prior_covariance = decov(regularization = 2), 
  adapt_delta = 0.99,
  chains = 4)

samples_text_rt <- m_rt %>% 
  as.data.frame() %>% as_tibble() %>% 
  dplyr::rename(bullseye = `(Intercept)`,
                face = conditionface,
                text = conditiontext,
                text_no_audio = `conditiontext-no-audio`) %>% 
  select(bullseye:text_no_audio)
```

## EWMA model

```{r read ewma output}
text_ewma <- c("speed_acc_adult_text_ewma_results.csv")
d_ewma_text <- text_ewma %>% purrr::map_df(read_ewma, path = ewma_path) 
```

### Cutoff points

```{r}
# Aggregate cutoffs for each participant
ss_cutoffs <- d_ewma_text %>% 
  filter(guess == "response") %>% 
  group_by(condition, subid) %>% 
  summarise_(cutoff = interp(~ min(x), x = as.name("rt"))) 

# fit model
m_ewma_cuts <- ss_cutoffs %>% 
  stan_glmer(log(cutoff) ~ condition + (condition | subid), 
  family = gaussian(),
  data = .,
  prior = normal(0, 2), 
  prior_intercept = normal(0, 5),
  prior_covariance = decov(regularization = 2), 
  adapt_delta = 0.99,
  chains = 4)

# extract samples
samples_text_ewma_cuts <- m_ewma_cuts %>% 
  as.data.frame() %>% as_tibble() %>% 
  dplyr::rename(bullseye = `(Intercept)`,
                face = conditionface,
                text = conditiontext,
                text_no_audio = `conditiontext-no-audio`) %>% 
  select(bullseye:text_no_audio)
```

### Prop guessing

```{r}
m_ewma_guess <- d_ewma_text %>% 
  stan_glmer(correct ~ condition + (condition|subid),
        data = .,
        family = binomial(link = "logit"), 
        prior = normal(0, 2),
        prior_intercept = normal(0, 1),
        prior_covariance = decov(regularization = 2), 
        adapt_delta = 0.99,
        chains = 4)

samples_text_ewma_guess <- m_ewma_guess %>% 
  as.data.frame() %>% as_tibble() %>% 
  dplyr::rename(asl = `(Intercept)`,
                face = stimuliFace,
                age_beta = months) %>% 
  select(asl:face, age_beta)
```


## Save posterior samples

```{r}
posteriors <- list(rt_text = samples_text_rt,
                   acc_text = samples_text_acc,
                   ewma_guess_text = samples_text_ewma_guess,
                   ewma_cuts_text = samples_text_ewma_cuts)

saveRDS(posteriors, file = here::here(write_path, "speed-acc-text-posterior-samples.rds"))
```
