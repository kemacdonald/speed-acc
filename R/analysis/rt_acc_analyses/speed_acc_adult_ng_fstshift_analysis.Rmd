---
title: "Speed-Acc Noise Gaze Analysis"
author: "Kyle MacDonald"
output: html_document
---

## Set up 

Here are some helpful links for understanding the workflow for analyzing data in R Markdown (what you're doing in this document!):

 * [Scripts](http://r4ds.had.co.nz/workflow-scripts.html)
 * An R Markdown [guide](https://docs.google.com/document/d/1ajv1VJqEheVws93tnzH-K7145vBKtwD3Az5pg3faRdw/edit?usp=sharing) that I wrote for the lab
 
```{r chunk_options, echo = F}
# code to clear workspace
rm(list=ls()) 

# set some global options
knitr::opts_chunk$set(warning=F, message=F, sanitize = T, 
                      fig.height=5, fig.width=8, echo=T, cache = F)
```

```{r}
# read in personal library of helper functions
source("../../helper_functions/libraries_and_functions.R")
```

## Load data

Section 11.2 from [this](http://r4ds.had.co.nz/data-import.html) chapter on data importing is great.

**KM note**: this way of reading the file will work, but it only will work on your computer since this part of the path [~/Desktop/Research/] is specific to where you saved the data. The solution is to use a relative path like I've done here. You can check out this [video](https://www.youtube.com/watch?v=fe6GA200dks) for more background.

```{r}
# read in the data using a relative path that starts from the analysis file directory
d <- read_csv("../../../data/3_final_merged_data/first_shifts/speed_acc_adult_ng_fstshift_tidy.csv")
```

## Check the data

The goal of this section is to make sure the data match our expectations, or in other words, we are "testing" our data. Usually this involves comparing a known value to the number actually in the data set. For example, I know how I ran 20 participants, do I have 20 unique participant IDs?

[This](http://r4ds.had.co.nz/transform.html) chapter from the book **R for Data Science** is a good reference for writing code to manipulate data to do data "sanity" checks.

How many participants in the dataset?  

**KM note**: Nice work on the checks! It made me catch a few errors in my data processing pipeline. Note that you could also write these series of commands as connected using pipes. Check [this](http://r4ds.had.co.nz/pipes.html) out for more information.

```{r}
by_id <- group_by(d, subid)
summary_by_id <- summarise(.data = by_id)
count(summary_by_id)
```

How many trials do we have for each participant?

```{r}
by_trial <- group_by(d, subid, tr.num)
summary_by_trial <- summarise(.data = by_trial)
count(summary_by_trial)
```

**Km note**: Looks like there are only 25 trials for *speed_acc_adult_ng-8*. Not sure what's going on? 

How many trials in each condition? 

```{r}
by_gaze_condition <- group_by(d, gaze_condition, subid, tr.num)
summary_by_gaze_condition <-summarise(.data = by_gaze_condition)
count(summary_by_gaze_condition)

by_noise_condition <- group_by(d, noise_condition, subid, tr.num)
summary_by_noise_condition <-summarise(.data = by_noise_condition)
count(summary_by_noise_condition)
```

**KM note**: Looks like we need to create a single variable that stores information about both the noise and gaze condition. 

```{r}
d <- d %>% mutate(condition_long = paste(gaze_condition, noise_condition, sep = "_"))
```

**KM note**: Now we can see how many trials are in each condition.

```{r}
d %>% 
  group_by(subid,condition_long) %>% 
  summarise(n = n()) %>% 
  kable()
```

TODO: Check out what's going on with #8

This looks like a data merging issue where #8's data. Not sure what's going on?

## Explore data via visualization

[This](http://r4ds.had.co.nz/data-visualisation.html) is a great book chapter on data visualization using the ggplot2 R package

### Visualize data distributions

My goal when I visualize the distribution of a variable is usually to check if there any data points that look like outliers (really different from the other values in the sample). There are more precise, quantitative ways to define outlier, but the visualization helps us spot them quickly. If some observations look really different, I then try to reason about why that might be the case: data entry error? equipment measurement error? 

What about Reaction Times (RT)?

**KM note**: Nice job! Small point, but there's no need to load the library in each chunk. Just need to do it once, which we usually do at the beginning of the document. Also, there's no need to wrap the `d` object in the `data.frame()` function since it is already a data frame.

```{r}
ggplot(d) + 
  geom_point(mapping = aes(x = subid, y = rt))
```

`geom_histogram()` is a good one for viewing the overall distribution of RTs in the experiment.

```{r}
ggplot(d, aes(x = rt)) +
  geom_histogram()
```

What about Accuracy? 

```{r}
ggplot(d) + 
  geom_bar(mapping = aes(x = subid, fill = shift_accuracy)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

**KM note**: This is a great exploratory plot! We can see that a couple of participants are doing "weird" things that we would want to investigate further. The only thing I changed was the angle of the x-axis text, so we can see the subids more easily. 

## filter the data

Let's filter out the participants who was not a native speaker of English

```{r}
d.filt <- d %>% filter(!(subid %in% c("speed_acc_adult_ng_1")))
```

Next, let's remove extreme RTs. 

```{r}
d.filt %<>% filter(rt <= 1.5)
```

### Visualize Accuracy

What is the overall accuracy of first shifts?

```{r}
ggplot(d.filt) + 
  geom_bar(mapping = aes(x = shift_accuracy))
```

What about the accuracy for each condition?

```{r}
ggplot(d.filt) + 
  geom_bar(mapping = aes(x = gaze_condition, fill = shift_accuracy))
```

```{r}
ggplot(d.filt) + 
  geom_bar(mapping = aes(x = noise_condition, fill = shift_accuracy))
```

Let's visualize accuracy collapsing across the gaze and noise conditions. First we are going to summarise to get a proportion correct for each participant and condition. Then we aggregate again to get an overall proportion correct for each condition. 

```{r}
# aggregate accuracy at the participant level
ss.acc <- d.filt %>% 
  filter(!is.na(shift_accuracy),
         shift_type %in% c("C_T", "C_D"),
         str_detect(condition_long, "no_noise")) %>% 
  group_by(gaze_condition, subid, shift_accuracy) %>% 
  summarise(n = n()) %>% 
  group_by(subid, gaze_condition) %>% 
  mutate(total_trials = sum(n),
         prop = round(n / total_trials, 2)) 
```

Now make a boxplot of the accuracy data for each condition. Note that we have to first filter out the proprotion "incorrect" rows, so we are only seeing the proprotion correct data.

```{r}
acc_boxplot <- ss.acc %>% 
  filter(shift_accuracy == "correct") %>% 
  ggplot(aes(x = gaze_condition, y = prop)) +
  geom_boxplot(width = 0.5, fill = "dodgerblue") +
  geom_jitter(width = 0.05, alpha = 0.3) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  labs(x = "Condition", y = "Prop. Correct") +
  theme(text = element_text(size = 18)) +
  ylim(0,1)
```

### Visualize Reaction Time

RT Boxplot

```{r}
ss.rt <- d.filt %>% 
  filter(!is.na(shift_accuracy),
         shift_type %in% c("C_T", "C_D"),
         str_detect(condition_long, "no_noise")) %>% 
  group_by(gaze_condition, subid) %>% 
  summarise(m_rt = mean(rt))
```

```{r}
rt_boxplot <- ss.rt %>% 
  ggplot(aes(x = gaze_condition, y = m_rt)) +
  geom_boxplot(width = 0.5, fill = "#de2d26") +
  geom_jitter(width = 0.05, alpha = 0.3) + 
  ylim(0,1) +
  labs(x = "Condition", y = "RT (sec)") +
  theme(text = element_text(size = 18))
```

```{r}
cowplot::plot_grid(rt_boxplot, acc_boxplot)
```


## RT Distributions

```{r}
acc_colors <- c("grey10", "black")
fill_vals <- c("grey90", "darkviolet")

p <- d %>% 
  filter(is.na(rt) == F,
         rt <= 4,
         str_detect(condition_long, "no_noise")) %>% 
  ggplot(aes(x = forcats::fct_rev(gaze_condition), y = rt)) +
  ggbeeswarm::geom_quasirandom(shape = 21, fill = "black", color = "black") + 
  labs(y = "RT (sec)", x = NULL) +
  theme_bw() +
  theme(legend.position = "right") + 
  theme(axis.title.x = element_text(size = 18, 
                                    face = "bold"), 
        axis.title.y = element_text(size = 18,
                                    face = "bold"), axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 18)) +
  coord_flip()

p
```


## Statistical models

We can talk more about this aspect of the anlaysis once you made some progress on data viz. 


