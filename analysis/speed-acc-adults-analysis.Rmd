---
title: "Speed-acc Adults Analysis"
author: "Kyle MacDonald"
date: "10/20/2016"
output: html_document
---

## Setup

Load libraries and read in tidy data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F, sanitize = T)
```

This script munges eye-tracking data for an experiment comparing speed-accuracy tradeoffs when establishing reference in real-time. We vary the information value and saliency of the center fixation and measure the effects on accuracy and RT.

```{r libraries} 
rm(list = ls())
library(langcog); library(lme4); library(directlabels)
library(lazyeval); library(yarrr); library(forcats); library(arm)
library(dplyr); library(readr); library(magrittr)
library(ggplot2); library(tidyr); library(knitr)
# plotting styles
theme_set(theme_bw())
```

```{r read data}
d <- read_csv("../data/3_final_merged_data/speed_acc_adult_timecourse_tidy.csv")
d.fs <- read_csv("../data/3_final_merged_data/speed_acc_adult_fstshift_tidy.csv")
```

## Visualize looking behavior 

Filter to get the anlaysis window (one second before the noun onset). Start is when the center fixation appeared. End is the end of the trial. 

```{r}
d.filt <- d %>% filter(t.stim > 0, t.stim <= 5) 
```

First, we generate curves that represent center, target, and distractor looking over time

Summarize data for each ROI for each participant and each time slice.

```{r}
# get number of trials looking at each gaze target for each time slice
ss.d <- d.filt %>% 
  group_by(subid, t.stim, condition, audio) %>% 
  summarise(count = ifelse(n() == 0, 0, n())) %>% 
  ungroup() %>% 
  mutate(subid = as.character(subid))

# get proportion looking by dividing the freq looking at each target by the total looking 
# derived in step 1 of this chunk
ss.d <- as.data.frame(xtabs(~ subid + audio + t.stim + target_looking + condition, 
                            data = d.filt),
                      stringsAsFactors = F) %>% 
  mutate(t.stim = as.numeric(t.stim)) %>% 
  left_join(x = ss.d, y = ., by = c("subid", "t.stim", "condition", "audio")) %>% 
  mutate(proportion_looking = Freq / count)
```

Get means and CIs for proportion looking at each time slice across particpants

```{r}
ms.means.timeslice <- ss.d %>% 
  group_by(t.stim, condition, audio, target_looking) %>% 
  summarise(mean = mean(proportion_looking, na.rm = T))
```

Now make the Tanenhaus style curves for each condition 

```{r, fig.width=10}
ggplot(aes(x = as.numeric(t.stim), y = mean, 
           color = condition), data = ms.means.timeslice) + 
  ylim(0,1) +
  xlim(-0.2,5) +
  geom_line() +
  facet_grid(target_looking~.) +
  xlab("Time in sec from onset of trial") +
  geom_vline(xintercept = mean(d$noun_onset_sec_1), linetype = "dashed") +
  geom_vline(xintercept = mean(d$sentence_onset_sec), linetype = "dashed") +
  ylab("Proportion looking") +
  guides(color = F, shape = F, linetype = F) +
  geom_dl(aes(label = condition), method = "first.bumpup") +
  annotate("text", label = "Sentence Onset", x = mean(d$sentence_onset_sec)-0.3, 
           y = 0.4, size = 4, colour = "dodgerblue") +
  annotate("text", label = "Noun Onset", x = mean(d$noun_onset_sec_1)-0.3, 
           y = 0.4, size =4 , colour = "dodgerblue")
```

## Standard "window" accuracy analyses

### Boxplot of proportion looking to each ROI as a function of condition.

First we need to get the proportion looking to each location for each trial for each participant.

```{r}
# get number of trials looking at each gaze target for each time slice
ss.d.tr <- d.filt %>% 
  filter(t.rel.sentence >= 0) %>% 
  group_by(subid, tr.num, condition, audio) %>% 
  summarise(count = ifelse(n() == 0, 0, n())) %>% 
  ungroup() %>% 
  mutate(subid = as.character(subid))

# get proportion looking by dividing the freq looking at each target by the total looking 
# derived in step 1 of this chunk
ss.d.tr <- as.data.frame(xtabs(~ subid + audio + tr.num + target_looking + condition, 
                            data = filter(d.filt, t.rel.sentence >= 0)),
                      stringsAsFactors = F) %>% 
  mutate(tr.num = as.numeric(tr.num)) %>% 
  left_join(x = ss.d.tr, y = ., by = c("subid", "tr.num", "condition", "audio")) %>% 
  mutate(proportion_looking = Freq / count)
```

Now we can plot the trial level summarized looking data. Here I'm using a pirate plot from the yarrr package created by Nathaniel Phillips. The plot shows raw data and information that helps with inference. There are 4 parts:

1. points, symbols representing the raw data (jittered horizontally)
2. bar, a vertical bar showing central tendencies
3. bean, a smoothed density (inspired by Kampstra and others (2008)) representing a smoothed density
4. inf, a rectangle representing an inference interval (e.g.; Bayesian Highest Density Interval or frequentist confidence interval)

```{r fig.width=10}
yarrr::pirateplot(formula = proportion_looking ~ condition + target_looking,
                  point.o = .1,
                  data = ss.d.tr,
                  main = "Looking behavior as a function of condition",
                  pal = "google")
```

Participants look less at the center fixation when it's a static bullseye, more when it's a face or text with audio, and the most when it is just text. Note that both target and distracter looking are higher for bullseye condition because they are more likely to be looking at either picture during the time before noun onset. This tells me that window accuracy is not the best metric here (at least over the entire trial window).

## First shift anlayses (RT, Accuracy, EWMA, and DDM)

### RT analysis

First, we analyze RT and accuracy of first shifts that are computed from noun onset.

```{r}
d.fs %>% 
  filter(shift_type %in% c("C_T", "C_D")) %>% 
  group_by(shift_type, response_onset_type) %>% 
  count() %>% 
  kable()
```

Regardless of when you start the clock, only ~5% of shifts are incorrect, This makes sense since this is an easy task for adults. 

```{r summarize RT for correct and incorrect shifts}
ss.d.rt <- d.fs %>% 
  filter(shift_type %in% c("C_T", "C_D"), 
         response_onset_type %in% c("noun", "sentence")) %>% 
  select(subid, tr.num, condition, shift_accuracy, rt, response_onset_type) %>% 
  unique()

ms.rt <- ss.d.rt %>% 
  group_by(condition, shift_accuracy, response_onset_type) %>% 
  summarise(med = median(rt))
```

Distribution of RTs for correct vs. incorrect shifts from noun onset and from sentence onset

```{r, fig.width = 8, fig.height = 8}
ggplot(aes(x = rt, fill = shift_accuracy), data = ss.d.rt) +
  #geom_density(alpha = 0.7, adjust = 1.5) + 
  geom_histogram(alpha = 0.7, position = "identity") +
  facet_grid(condition~response_onset_type) +
  geom_vline(aes(xintercept = med, color = shift_accuracy), size = 1, lty = "dashed", 
             data = ms.rt) +
  guides(color = F) + 
  ylab("Density") +
  xlab("RT (sec)") +
  scale_fill_manual(values = c("darkorange", "dodgerblue")) +
  scale_color_manual(values = c("darkorange", "dodgerblue")) +
  theme(text = element_text(size=18),
        legend.position = "top",
        panel.margin = unit(2, "lines"))
```

What should we do with shifts that happen before noun onset? My thought is to feed them into the EWMA, but not into the summary analyses and the DDM fits.

#### Plot RT by condition

First we aggregate median RT for each participant.

```{r}
ss.rt <- ss.d.rt %>% 
  filter(response_onset_type == "noun") %>% 
  group_by(condition, subid, shift_accuracy) %>% 
  summarise(med_rt = median(rt))
```

Then we make a boxplot.

```{r}
ggplot(aes(x = condition, y = med_rt, fill = shift_accuracy), data = ss.rt) +
  geom_boxplot(width = 0.7) +
  geom_point(alpha = 0.6, position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.5)) +
  scale_fill_manual(values = c("darkorange", "dodgerblue")) 
```


## EWMA filter to model guessing behavior 

Here's the EWMA function for modeling guessing behavior over time.

```{r ewma function}
ewma_function <- function(df, rt_column = "RT", lambda = .01, cs = .5, sigma = .5, L = 1.5) {
  df <- arrange_(df, rt_column)
  results <- data.frame(rt = numeric(), cs = numeric(), ucl = numeric(), 
                        cond = character(), stringsAsFactors = F)
  
  for(row in 1:nrow(df)) {
    subj <- df[row, ]
    cond <- as.character(subj["condition"])
    acc <- as.integer(subj["correct"])
    rt <- as.numeric(subj["RT"])
    cs <- lambda*acc + (1-lambda)*cs # weighted average for each rt (row)
    ucl <- .5 + L*sigma*sqrt((lambda/(2 - lambda))*(1-((1-lambda)^(2*row)))) # threshold
    # add emwa params to results data frame
    subj$cs <- cs
    subj$ucl <- ucl
    results <- rbind(results, subj)
  }
  return(results)
}
```

First we munge the data to feed into the EWMA function.

```{r ewma munge}
d.fs.ewma <- d.fs %>% 
  select(subid, tr.num, shift_accuracy, rt, response_onset_type, condition) %>% 
  filter(is.na(rt) == F, response_onset_type == "noun") %>% 
  mutate(correct = ifelse(shift_accuracy == "correct", 1, 0), 
         RT = rt)
```

Fit the EWMA model and plot results.

```{r ewma model}
ewma.results <- d.fs.ewma %>% 
  group_by(condition) %>% 
  do(ewma_function(., rt_column = "RT", L = 2.5, lambda = .05)) %>% 
  mutate(rt = round(as.numeric(rt), 2),
         cs = round(as.numeric(cs), 2),
         ucl = round(as.numeric(ucl), 2),
         guess = ifelse(cs < ucl, "guess", "response"),
         guess_num = ifelse(guess == "response", 1, 0),
         ucl_bound = abs(ucl-cs))

cutoffs <- ewma.results %>% 
  filter(guess == "response") %>% 
  group_by(condition) %>% 
  summarise_(cutoff = interp(~ min(x), x = as.name("rt"))) %>% 
  group_by(condition) %>% 
  summarise(cutoff = median(cutoff))

```

```{r ewma plot, fig.height=8}
ggplot(data = ewma.results) +
  geom_line(aes(x = rt, y = cs, color = "Moving Average", group = 1), size = 1) +
  geom_line(aes(x = rt, y = ucl, color = "Threshold Limit"), size = 0.5) +
  geom_vline(aes(xintercept = cutoff), linetype = 2, data = cutoffs) +
  geom_hline(yintercept = 0.5, linetype = "solid") +
  ylab("Moving Average") + xlab("Reaction Time") +
  facet_grid(condition~.) +
  scale_color_manual(values = c("darkorange", "dodgerblue")) 
```

What do we see here? The bullseye condition crosses the threshold after 1 second. The face, text, and text-audio all cross the threshold earlier in the window. Text-no-audio crosses earliest given these parameters of the EWMA model. Finally, in the text-no-audio condition there aren't any early RTs to model. How should we add this information to the analysis?

What we can do is compute the proportion of shifts that were categorized as a "fast guess" compared to a "valid response" for each participant for each condition.

```{r}
ss.guessing.prop <- ewma.results %>% 
  group_by(subid, condition, guess) %>% 
  summarise(count = n()) %>% 
  mutate(prop.guessing = round(count / sum(count), 2))
```

Boxplot of proportion guessing by condition.

```{r}
ggplot(aes(x = fct_rev(condition), y = prop.guessing), 
       data = filter(ss.guessing.prop, guess == "guess")) +
  geom_boxplot(fill = "dodgerblue", width = 0.7) +
  geom_jitter(width= 0.2, alpha = 0.7) + 
  labs(
    x = "Condition",
    y = "Prop. Guessing"
  ) +
  coord_flip()
```

This looks like what we saw in the EWMA control charts: bullseye is mostly guesses, whereas face, text, and text-no-audio are mostly valid resposnes. However, this analysis still does not caputre one effect in the EWMA chart, which is the amount of *time* spent in a guessing phase vs. a valid response phase.

To get at this effect, we compute the difference in time from first guessing response to first valid response for each participant for each condition. 

```{r}
compute_guessing_window <- function(sub_df) {
  # compute guessing window
  crit.window.responses <- sub_df %>%
    ungroup() %>% 
    select(guess, RT) %>% 
    group_by(guess) %>% 
    summarise(min_rt = min(RT)) %>% 
    arrange(min_rt) 
  # if "resposne" not in the vector then ss was guessing on all shifts in that condition 
  if (!("response" %in% crit.window.responses$guess)) {
    # just use the diff between earliest and latest shifts
    sub_df$time_guessing <- max(sub_df$RT) - min(sub_df$RT) 
  } else {
    # here we use the diff between the earliest shift and the earliest "valid" (non-guess) shift
    sub_df$time_guessing <- max(crit.window.responses$min_rt) - min(crit.window.responses$min_rt)  
  }
  return(sub_df)
}
```

```{r}
ss.guessing.window <- ewma.results %>% 
  group_by(subid, condition) %>% 
  do(compute_guessing_window(.)) %>% 
  select(subid, time_guessing, condition) %>%
  mutate(time_guessing = as.numeric(time_guessing)) %>% 
  unique()
```

Boxplot of time guessing across the different conditions.

```{r}
ggplot(aes(x = fct_rev(condition), y = time_guessing), data = ss.guessing.window) +
  geom_boxplot(fill = "dodgerblue", width = 0.7) +
  geom_jitter(width= 0.2, alpha = 0.7) +
  labs(
    x = "Condition",
    y = "Guesing Window (sec)"
  ) +
  coord_flip()
```

## Stats for EWMA parameters

Model the effect of condition on the the trial-level guessing vs. non-guessing responses. Note that the outcome measure -- guessing behavior -- is determined by the EWMA control process model described above. 

In this model, we include a fixed effect of condition and a random effect of participant. We also test the following contrasts of interest: 

* Bullseye vs. Face/Text/Text-no-audio
* Text vs. No-text
* Text-audio vs. Text-no-audio
* Bullseye vs. Face

```{r glmer guessing behavior}
# contrast coding to test comparisons of interest
# todo: fix contrast coding so model is not rank deficient
ewma.results$condition_fact <- as.factor(ewma.results$condition)
contrasts(ewma.results$condition_fact) <- cbind("noaudio_vs_audio" = c(1, 1, 1, -3), 
                                      "notext_vs_text" = c(1, 1, -1, -1),
                                      "textaudio_vs_textnoaudio" = c(0, 0, 1, -1),
                                      "bullseye_vs_face" = c(1, -1, 0, 0))

m1 <- glmer(guess_num ~ condition_fact + (1|subid) + (condition|subid), 
            data = ewma.results,
            nAGQ = 0,
            family = binomial)
```

```{r anova guessing window}
summary(aov(time_guessing ~ condition, data = ss.guessing.window))
```


## Fit Diffusion models


## Stats for DDM parameters

Repeated measures ANOVA. Liner mixed effects model doesn't add much value here since we are doing inference over the parameter estimates for each participant (i.e., we only have 3 data points for each ss).
