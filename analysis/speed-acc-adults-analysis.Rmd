---
title: "Speed-acc Adults Analysis"
author: "Kyle MacDonald"
date: "10/20/2016"
output: html_document
---

## Setup

Load libraries and read in tidy data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F, sanitize = T)
```

This script munges eye-tracking data for an experiment comparing speed-accuracy tradeoffs when establishing reference in real-time. We vary the information value and saliency of the center fixation and measure the effects on accuracy and RT.

```{r setup2} 
rm(list = ls())
library(dplyr); library(readr); library(magrittr)
library(ggplot2); library(tidyr); library(knitr)
library(langcog); library(lme4); library(directlabels)
library(lazyeval); library(yarrr)
theme_set(theme_bw())
```

```{r read data}
d <- read_csv("../data/3_final_merged_data/speed_acc_processed_adult_tidy_data.csv")
```

## Visualize looking behavior 

Filter to get the anlaysis window (one second before the noun onset). Start is when the center fixation appeared. End is the end of the trial. We also only select one of the response types since these data are in long format and effectively the looking time data appear three times.

```{r}
d.filt <- d %>% filter(t.stim > 0, t.stim <= 5, response_type == "noun.onset") 
```

First, we generate curves that represent center, target, and distractor looking over time

Summarize data for each ROI for each participant and each time slice.

```{r}
# get number of trials looking at each gaze target for each time slice
ss.d <- d.filt %>% 
  group_by(subid, t.stim, condition, audio) %>% 
  summarise(count = ifelse(n() == 0, 0, n())) %>% 
  ungroup() %>% 
  mutate(subid = as.character(subid))

# get proportion looking by dividing the freq looking at each target by the total looking 
# derived in step 1 of this chunk
ss.d <- as.data.frame(xtabs(~ subid + audio + t.stim + target_looking + condition, 
                            data = d.filt),
                      stringsAsFactors = F) %>% 
  mutate(t.stim = as.numeric(t.stim)) %>% 
  left_join(x = ss.d, y = ., by = c("subid", "t.stim", "condition", "audio")) %>% 
  mutate(proportion_looking = Freq / count)
```

Get means and CIs for proportion looking at each time slice across particpants

```{r}
ms.means.timeslice <- ss.d %>% 
  group_by(t.stim, condition, audio, target_looking) %>% 
  summarise(mean = mean(proportion_looking, na.rm = T))
```

Now make the Tanenhaus style curves for each condition 

```{r, fig.width=10}
ggplot(aes(x = as.numeric(t.stim), y = mean, 
           color = condition), data = ms.means.timeslice) + 
  ylim(0,1) +
  xlim(-0.2,5) +
  geom_line() +
  facet_grid(target_looking~.) +
  xlab("Time in sec from onset of trial") +
  geom_vline(xintercept = mean(d$noun_onset_sec_1), linetype = "dashed") +
  geom_vline(xintercept = mean(d$sentence_onset_sec), linetype = "dashed") +
  ylab("Proportion looking") +
  guides(color = F, shape = F, linetype = F) +
  geom_dl(aes(label = condition), method = "first.bumpup") +
  annotate("text", label = "Sentence Onset", x = mean(d$sentence_onset_sec)-0.3, 
           y = 0.4, size = 4, colour = "dodgerblue") +
  annotate("text", label = "Noun Onset", x = mean(d$noun_onset_sec_1)-0.3, 
           y = 0.4, size =4 , colour = "dodgerblue")
```

## Standard "window" accuracy analyses

### Boxplot of proportion looking to each ROI as a function of condition.

First we need to get the proportion looking to each location for each trial for each participant.

```{r}
# get number of trials looking at each gaze target for each time slice
ss.d.tr <- d.filt %>% 
  filter(t.rel.sentence >= 0) %>% 
  group_by(subid, tr.num, condition, audio) %>% 
  summarise(count = ifelse(n() == 0, 0, n())) %>% 
  ungroup() %>% 
  mutate(subid = as.character(subid))

# get proportion looking by dividing the freq looking at each target by the total looking 
# derived in step 1 of this chunk
ss.d.tr <- as.data.frame(xtabs(~ subid + audio + tr.num + target_looking + condition, 
                            data = filter(d.filt, t.rel.sentence >= 0)),
                      stringsAsFactors = F) %>% 
  mutate(tr.num = as.numeric(tr.num)) %>% 
  left_join(x = ss.d.tr, y = ., by = c("subid", "tr.num", "condition", "audio")) %>% 
  mutate(proportion_looking = Freq / count)
```

Now we can plot the trial level summarized looking data. Here I'm using a pirate plot from the yarrr package created by Nathaniel Phillips. The plot shows raw data and information that helps with inference. There are 4 parts:

1. points, symbols representing the raw data (jittered horizontally)
2. bar, a vertical bar showing central tendencies
3. bean, a smoothed density (inspired by Kampstra and others (2008)) representing a smoothed density
4. inf, a rectangle representing an inference interval (e.g.; Bayesian Highest Density Interval or frequentist confidence interval)

```{r fig.width=10}
yarrr::pirateplot(formula = proportion_looking ~ condition + target_looking,
                  point.o = .1,
                  data = ss.d.tr,
                  main = "Looking behavior as a function of condition",
                  pal = "google")
```

Participants look less at the center fixation when it's a static bullseye, more when it's a face or text with audio, and the most when it is just text. Note that both target and distracter looking are higher for bullseye condition because they are more likely to be looking at either picture during the time before noun onset. This tells me that window accuracy is not the best metric here (at least over the entire trial window).

## First shift anlayses (RT, Accuracy, EWMA, and DDM)

### RT analysis

First, we analyze RT and accuracy of first shifts that are computed from noun onset.

```{r}
d.fs <- d %>% 
  select(subid, tr.num, response_type, rt, shift_type, shift_accuracy, condition) %>% 
  unique()
```

Create a barplot of the different shift types for the different critical onsets.

```{r, fig.width=8}
d.fs %>% 
  group_by(shift_type, response_type) %>% 
  count() %>%
  mutate(prop = n / nrow(d.fs)) %>% 
  filter(shift_type != "no_shift") %>% 
  ggplot(aes(x=response_type, y = prop)) +
  geom_bar(stat = "identity") +
  facet_wrap(~shift_type)
```

Regardless of when you start the clock, only ~5% of shifts are incorrect, This makes sense since this is an easy task for adults. 

```{r summarize RT for correct and incorrect shifts}
ss.d.rt <- d.fs %>% 
  filter(shift_type %in% c("C_T", "C_D"), response_type %in% c("noun.onset", "sentence.onset")) %>% 
  select(subid, tr.num, condition, shift_accuracy, rt, response_type) %>% 
  unique()
```

```{r}
ms.rt <- ss.d.rt %>% 
  group_by(condition, shift_accuracy, response_type) %>% 
  summarise(med = median(rt))
```

Distribution of RTs for correct vs. incorrect shifts from noun onset and from sentence onset

```{r, fig.width = 8, fig.height = 8}
ggplot(aes(x = rt, fill = shift_accuracy), data = ss.d.rt) +
  #geom_density(alpha = 0.7, adjust = 1.5) + 
  geom_histogram(alpha = 0.7, position = "identity") +
  facet_grid(condition~response_type) +
  geom_vline(aes(xintercept = med, color = shift_accuracy), size = 1, lty = "dashed", 
             data = ms.rt) +
  guides(color = F) + 
  ylab("Density") +
  xlab("RT (sec)") +
  scale_fill_manual(values = c("darkorange", "dodgerblue")) +
  scale_color_manual(values = c("darkorange", "dodgerblue")) +
  theme(text = element_text(size=18),
        legend.position = "top",
        panel.margin = unit(2, "lines"))
```

What should we do with shifts that happen before noun onset? My thought is to feed them into the EWMA, but not into the summary analyses and the DDM fits.

#### Plot RT by condition

First we aggregate median RT for each participant.

```{r}
ss.rt <- ss.d.rt %>% 
  filter(response_type == "noun.onset") %>% 
  group_by(condition, subid) %>% 
  summarise(med = median(rt))
```

Then we make a boxplot.

```{r}
pirateplot(med ~ condition, 
           pal = "google", ylim = c(0,1),
           data = ss.rt)
```


## EWMA filter to model guessing behavior 

Here's the EWMA function for modeling guessing behavior over time.

```{r ewma function}
ewma_function <- function(df, rt_column = "RT", lambda = .01, cs = .5, sigma = .5, L = 1.5) {
  df <- arrange_(df, rt_column)
  results <- data.frame(rt = numeric(), cs = numeric(), ucl = numeric(), 
                        cond = character(), stringsAsFactors = F)
  
  for(row in 1:nrow(df)) {
    subj <- df[row, ]
    cond <- as.character(subj["condition"])
    acc <- as.integer(subj["correct"])
    rt <- as.numeric(subj["RT"])
    cs <- lambda*acc + (1-lambda)*cs # weighted average for each rt (row)
    ucl <- .5 + L*sigma*sqrt((lambda/(2 - lambda))*(1-((1-lambda)^(2*row)))) # threshold
    # add emwa params to results data frame
    subj$cs <- cs
    subj$ucl <- ucl
    results <- rbind(results, subj)
  }
  return(results)
}
```

First we munge the data to feed into the EWMA function.

```{r}
d.fs.ewma <- d.fs %>% 
  select(subid, tr.num, shift_accuracy, rt, response_type, condition) %>% 
  filter(is.na(rt) == F, response_type == "noun.onset") %>% 
  mutate(correct = ifelse(shift_accuracy == "correct", 1, 0), 
         RT = rt)
```

Fit the EWMA model and plot results.

```{r, fig.height=8}
ewma.results <- d.fs.ewma %>% 
  group_by(condition) %>% 
  do(ewma_function(., rt_column = "RT", L = 2.5, lambda = .05)) %>% 
  mutate(rt = round(as.numeric(rt), 2),
         cs = round(as.numeric(cs), 2),
         ucl = round(as.numeric(ucl), 2),
         guess = ifelse(cs < ucl, "guess", "response"),
         ucl_bound = abs(ucl-cs))

cutoffs <- ewma.results %>% 
  filter(guess == "response") %>% 
  group_by(condition) %>% 
  summarise_(cutoff = interp(~ min(x), x = as.name("rt"))) %>% 
  group_by(condition) %>% 
  summarise(cutoff = median(cutoff))


ggplot(data = ewma.results) +
  geom_line(aes(x = rt, y = cs, color = "cs", group = 1)) +
  geom_line(aes(x = rt, y = ucl, color = "UCL")) +
  geom_vline(aes(xintercept = cutoff), linetype = 2, data = cutoffs) +
  ylab("Moving Average") + xlab("Reaction Time") +
  facet_grid(condition~.) 
```

What do we see? The bullseye condition crosses the threshold after 1 second. The face, text, and text-audio all cross the threshold earlier in the window. Text-no-audio crosses earliest given these parameters of the EWMA model. Finally, in the text-no-audio condition, there are no early RTs to model. 

How should we add this information to the model?


## Stats for EWMA parameters

Help! 

```{r}
ss.ewma <- ewma.results %>% 
  filter(guess == "response") %>% 
  group_by(condition, subid) %>% 
  summarise_(cutoff = interp(~ min(x), x = as.name("rt")))

ms.ewma <- ss.ewma %>% 
  group_by(condition) %>% 
  multi_boot_standard(column = "cutoff", empirical_function = "mean")
```

```{r}
pirateplot(cutoff ~ condition, data = ss.ewma)
```

## Fit Diffusion models


## Stats for DDM parameters

Repeated measures ANOVA. Liner mixed effects model doesn't add much value here since we are doing inference over the parameter estimates for each participant (i.e., we only have 3 data points for each ss).
